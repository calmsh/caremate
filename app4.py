import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import warnings
import io
import asyncio
import edge_tts  # ì¶”ê°€


# --- AI ë° ìŒì„± ê¸°ëŠ¥ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ ---
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from streamlit_mic_recorder import speech_to_text

warnings.filterwarnings("ignore")

# ---------------------------------------------------------
# [ë³´ì•ˆ ì„¤ì • ì˜ì—­] - API í‚¤ë¥¼ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš” (ì‚¬ìš©ìì—ê²ŒëŠ” ë³´ì´ì§€ ì•ŠìŒ)
# ---------------------------------------------------------
OPENAI_API_KEY = "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"

# --- ë””ìì¸ ì„¤ì • ---
STYLE_CONFIG = {
 "corner_radius": "25px",      
 "border_width": "1px",
 "border_color": "#e2e8f0",
 "fg_color": "#FFFFFF",
 "bg_color": "#F0F9F6"
}

LEVEL_THEMES = {
 "ë†’ìŒ": {"color": "#ef4444", "bg": "#fee2e2", "emoji": "ğŸ”´"},
 "ì¤‘ê°„": {"color": "#f59e0b", "bg": "#fef3c7", "emoji": "ğŸŸ¡"},
 "ë‚®ìŒ": {"color": "#22c55e", "bg": "#dcfce7", "emoji": "ğŸŸ¢"}  
}

st.set_page_config(page_title="ì¼€ì–´ë©”ì´íŠ¸ - AI ë§Œì„±ì§ˆí™˜ ì˜ˆì¸¡", layout="centered", page_icon="ğŸ¥")

# --- ëª¨ë¸ ë¡œë“œ ---
@st.cache_resource
def load_models():
 if not os.path.exists('health_models.pkl'):
  st.error("âŒ ëª¨ë¸ íŒŒì¼(health_models.pkl)ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
  st.stop()
 
 models = joblib.load('health_models.pkl')
 
 # ë²„ì „ í˜¸í™˜ì„± íŒ¨ì¹˜
 for name, info in models.items():
  final_model = info['pipeline'].steps[-1][1]
  if 'LogisticRegression' in str(type(final_model)):
   if not hasattr(final_model, 'multi_class'):
    final_model.multi_class = 'ovr'
  if hasattr(final_model, 'estimators_'):
   for est in final_model.estimators_:
    actual_est = est.steps[-1][1] if hasattr(est, 'steps') else est
    if 'LogisticRegression' in str(type(actual_est)):
     if not hasattr(actual_est, 'multi_class'):
      actual_est.multi_class = 'ovr'
 
 return models

MODELS = load_models()

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'step' not in st.session_state:
 st.session_state.step = 1
if 'sub_step' not in st.session_state:
 st.session_state.sub_step = 1
if 'q_idx' not in st.session_state:
 st.session_state.q_idx = 0
if 'data_confirmed' not in st.session_state:
 st.session_state.data_confirmed = False
if 'user_data' not in st.session_state:
 st.session_state.user_data = {
  "name": "", "gender": "ë‚¨ì„±", "age": 70, "height": 160, "weight": 60,
  "diseases": [], "family_history": [], "edu": "ëŒ€ì¡¸ ì´ìƒ", "marry": "ê¸°í˜¼",
  "incm": "ìƒ", "alcohol": "ì•„ë‹ˆì˜¤", "sleep_time": 7
 }
if 'survey_answers' not in st.session_state:
 st.session_state.survey_answers = {"PHQ9": {}, "GAD7": {}, "BP1": {}, "EQ5D": {}}
if 'chat_history' not in st.session_state:
 st.session_state.chat_history = []

# --- CSS ìŠ¤íƒ€ì¼ ---
st.markdown(f"""
<style>
 @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700&display=swap');
 
 .stApp {{ background-color: {STYLE_CONFIG['bg_color']} !important; font-family: 'Noto Sans KR', sans-serif; }}
 .block-container {{ max-width: 700px !important; padding: 3rem 1rem !important; }}
 
 [data-testid="stVerticalBlock"] > div:has(div.card-content) {{
  background-color: white !important;
  padding: 40px !important;
  border-radius: {STYLE_CONFIG['corner_radius']} !important;
  border: {STYLE_CONFIG['border_width']} solid {STYLE_CONFIG['border_color']} !important;
  box-shadow: 0 10px 30px rgba(0,0,0,0.05) !important;
 }}
 
 .disease-item-card {{
  background-color: white;
  border-radius: 18px;
  padding: 22px;
  margin-bottom: 15px;
  border: 1px solid #edf2f7;
  box-shadow: 0 2px 8px rgba(0,0,0,0.04);
 }}
 
 .chat-bubble-ai {{ background-color: #f1f5f9; padding: 12px; border-radius: 15px; margin-bottom: 10px; color: #334155; }}
 .chat-bubble-user {{ background-color: #22c55e; padding: 12px; border-radius: 15px; margin-bottom: 10px; color: white; text-align: right; }}

 /* ì¹´ë“œí˜• ì„¤ë¬¸ ë‹µë³€ ê³µí†µ ë””ìì¸ */
 div[role="radiogroup"] {{
  gap: 10px !important;
 }}
 
 div[role="radiogroup"] > label {{
  background-color: white !important;
  border: 1px solid #e2e8f0 !important;
  border-radius: 12px !important;
  padding: 10px 15px !important;
  margin-bottom: 5px !important;
  width: 100% !important;
  display: flex !important;
  align-items: center !important;
  transition: all 0.2s ease !important;
 }}
 
 div[role="radiogroup"] > label:hover {{
  border-color: #22c55e !important;
 }}

 div[role="radiogroup"] > label[data-checked="true"] {{
  border-color: #ff4b4b !important;
  background-color: #fffafa !important;
 }}

 div[role="radiogroup"] > label[data-checked="true"] div[data-testid="stMarkdownContainer"] p {{
  color: #ff4b4b !important;
  font-weight: 600 !important;
 }}

 /* --- í•µì‹¬ ìˆ˜ì •: ì„±ë³„(Gender) ë²„íŠ¼ë§Œ ìˆ˜í‰ìœ¼ë¡œ ê°•ì œ --- */
 /* ì²« ë²ˆì§¸ ì»¬ëŸ¼(ì„±í•¨) ì˜†ì˜ ë‘ ë²ˆì§¸ ì»¬ëŸ¼(ì„±ë³„) ë¼ë””ì˜¤ ê·¸ë£¹ë§Œ íƒ€ê²ŸíŒ… */
 div[data-testid="stHorizontalBlock"] > div:nth-child(2) div[role="radiogroup"] {{
  flex-direction: row !important;
  display: flex !important;
  flex-wrap: wrap !important;
 }}
 
 div[data-testid="stHorizontalBlock"] > div:nth-child(2) div[role="radiogroup"] > label {{
  width: auto !important;
  flex: 1 !important;
  min-width: 80px !important;
 }}

 button[kind="primary"] {{
  background-color: #ff4b4b !important;
  border: none !important;
 }}
</style>
""", unsafe_allow_html=True)

# --- í•µì‹¬ í•¨ìˆ˜: ì„¤ë¬¸ ì ìˆ˜ ê³„ì‚° ---
def calculate_scores():
 phq_mapping = {"ì „í˜€ ì•„ë‹ˆë‹¤": 0, "ì—¬ëŸ¬ ë‚  ë™ì•ˆ": 1, "ì¼ì£¼ì¼ ì´ìƒ": 2, "ê±°ì˜ ë§¤ì¼": 3, "ëª¨ë¦„, ë¬´ì‘ë‹µ": 0}
 phq = 0
 for v in st.session_state.survey_answers['PHQ9'].values():
  for key, val in phq_mapping.items():
   if key in v:
    phq += val
    break
 
 gad_mapping = {"ì „í˜€ ì•„ë‹ˆë‹¤": 0, "ë©°ì¹  ë™ì•ˆ": 1, "7ì¼ ì´ìƒ": 2, "ê±°ì˜ ë§¤ì¼": 3}
 gad = 0
 for v in st.session_state.survey_answers['GAD7'].values():
  for key, val in gad_mapping.items():
   if key in v:
    gad += val
    break
 
 bp1_score = 1
 if st.session_state.survey_answers['BP1']:
  ans = list(st.session_state.survey_answers['BP1'].values())[0]
  bp1_score = int(ans.split(".")[0]) if "." in ans else 1
 
 eq_ans = []
 for v in st.session_state.survey_answers['EQ5D'].values():
  if v:
   num = int(v.split(".")[0]) if "." in v else 1
   eq_ans.append(num)
  else:
   eq_ans.append(1)
 
 while len(eq_ans) < 5:
  eq_ans.append(1)
 
 m2, m3 = (1, 0) if eq_ans[0]==2 else (0, 1) if eq_ans[0]==3 else (0, 0)
 sc2, sc3 = (1, 0) if eq_ans[1]==2 else (0, 1) if eq_ans[1]==3 else (0, 0)
 ua2, ua3 = (1, 0) if eq_ans[2]==2 else (0, 1) if eq_ans[2]==3 else (0, 0)
 pd2, pd3 = (1, 0) if eq_ans[3]==2 else (0, 1) if eq_ans[3]==3 else (0, 0)
 ad2, ad3 = (1, 0) if eq_ans[4]==2 else (0, 1) if eq_ans[4]==3 else (0, 0)
 n3 = 1 if 3 in eq_ans else 0
 
 eq5d = 1 - (0.05 + 0.096*m2 + 0.418*m3 + 0.046*sc2 + 0.209*sc3 +
     0.038*ua2 + 0.192*ua3 + 0.058*pd2 + 0.278*pd3 +
     0.062*ad2 + 0.19*ad3 + 0.05*n3)
 
 return phq, gad, bp1_score, eq5d

# --- í•µì‹¬ í•¨ìˆ˜: AI ì˜ˆì¸¡ ---
def get_predictions():
 u = st.session_state.user_data
 bmi = u['weight'] / ((u['height']/100)**2)
 phq, gad, bp1, eq5d = calculate_scores()
 
 full_data = {
  'age': u['age'],
  'sex': 1 if u['gender'] == "ë‚¨ì„±" else 2,
  'edu': {"ì´ˆì¡¸ ì´í•˜": 1, "ì¤‘ì¡¸": 2, "ê³ ì¡¸": 3, "ëŒ€ì¡¸ ì´ìƒ": 4}.get(u['edu'], 3),
  'marry': {"ê¸°í˜¼": 1, "ë¯¸í˜¼": 2, "ì´í˜¼/ì‚¬ë³„/ê¸°íƒ€": 3}.get(u['marry'], 1),
  'FH_HE': 1 if "ê³ í˜ˆì••" in u['family_history'] else 0,
  'FH_DB': 1 if "ë‹¹ë‡¨ë³‘" in u['family_history'] else 0,
  'FH_DY': 1 if "ì´ìƒì§€í˜ˆì¦" in u['family_history'] else 0,
  'FH_HAA': 1 if "ë‡Œì¡¸ì¤‘" in u['family_history'] else 0,
  'HE_BMI': bmi,
  'alcohol': 1 if u['alcohol'] == "ì˜ˆ" else 0,
  'mh_PHQ_S': phq,
  'mh_GAD_S': gad,
  'BP1': bp1,
  'EQ5D': eq5d,
  'sleep_time_wy': u['sleep_time'],
  'incm': {"í•˜": 1, "ì¤‘í•˜": 2, "ì¤‘ìƒ": 3, "ìƒ": 4}.get(u['incm'], 4)
 }
 
 predictions = {}
 for disease_name, model_info in MODELS.items():
  input_row = [full_data.get(feature, 0) for feature in model_info['features']]
  input_df = pd.DataFrame([input_row], columns=model_info['features'])
  prob = model_info['pipeline'].predict_proba(input_df)[0, 1]
  
  predictions[disease_name] = {
   "prob": prob,
   "threshold": model_info['threshold']
  }
 return predictions

# --- STEP 1: ê±´ê°• ì •ë³´ ì…ë ¥ ---
if st.session_state.step == 1:
 with st.container():
  st.markdown('<div class="card-content">', unsafe_allow_html=True)
  st.markdown('<h2 style="text-align:center; margin-bottom:30px;">ğŸ¥ ì¼€ì–´ë©”ì´íŠ¸</h2>', unsafe_allow_html=True)
  
  # c1(ì„±í•¨), c2(ì„±ë³„) -> CSSì—ì„œ nth-child(2)ë¥¼ í†µí•´ ì„±ë³„ë§Œ ìˆ˜í‰ ë°°ì¹˜
  c1, c2 = st.columns(2)
  with c1:
   name = st.text_input("ì„±í•¨", value=st.session_state.user_data["name"])
  with c2:
   gender = st.radio("ì„±ë³„", ["ë‚¨ì„±", "ì—¬ì„±"],
       index=0 if st.session_state.user_data["gender"]=="ë‚¨ì„±" else 1,
       horizontal=True)
  
  c3, c4 = st.columns(2)
  with c3:
   edu = st.selectbox("êµìœ¡ ìˆ˜ì¤€", ["ì´ˆì¡¸ ì´í•˜", "ì¤‘ì¡¸", "ê³ ì¡¸", "ëŒ€ì¡¸ ì´ìƒ"], index=3)
  with c4:
   marry = st.selectbox("ê²°í˜¼ ì—¬ë¶€", ["ê¸°í˜¼", "ë¯¸í˜¼", "ì´í˜¼/ì‚¬ë³„/ê¸°íƒ€"], index=0)
  
  st.divider()
  
  col_a, col_b, col_c = st.columns(3)
  with col_a:
   age = st.number_input("ë‚˜ì´ (ì„¸)", min_value=1, max_value=120,
            value=st.session_state.user_data["age"])
  with col_b:
   height = st.number_input("í‚¤ (cm)", min_value=50, max_value=250,
             value=st.session_state.user_data["height"])
  with col_c:
   weight = st.number_input("ëª¸ë¬´ê²Œ (kg)", min_value=20, max_value=200,
             value=st.session_state.user_data["weight"])
  
  col_d, col_e, col_f = st.columns(3)
  with col_d:
   incm = st.selectbox("ì†Œë“ ìˆ˜ì¤€", ["í•˜", "ì¤‘í•˜", "ì¤‘ìƒ", "ìƒ"], index=3)
  with col_e:
   # ìŒì£¼ ì—¬ë¶€ëŠ” col_eì— ìˆì–´ ìˆ˜ì§ ì¹´ë“œ í˜•íƒœë¥¼ ìœ ì§€í•¨
   alcohol = st.radio("ìŒì£¼ ì—¬ë¶€", ["ì•„ë‹ˆì˜¤", "ì˜ˆ"], horizontal=False)
  with col_f:
   sleep = st.number_input("í‰ê·  ìˆ˜ë©´ì‹œê°„ (ì‹œê°„)", min_value=0, max_value=24,
             value=st.session_state.user_data["sleep_time"])
  
  st.divider()
  
  diseases = st.multiselect("í˜„ì¬ ì§„ë‹¨ë°›ì€ ì§ˆí™˜",
               ["ê³ í˜ˆì••", "ë‹¹ë‡¨ë³‘", "ì´ìƒì§€í˜ˆì¦", "ë‡Œì¡¸ì¤‘"],
               default=st.session_state.user_data["diseases"])
  
  family_history = st.multiselect("ê°€ì¡±ë ¥ (ë¶€ëª¨/í˜•ì œìë§¤)",
               ["ê³ í˜ˆì••", "ë‹¹ë‡¨ë³‘", "ì´ìƒì§€í˜ˆì¦", "ë‡Œì¡¸ì¤‘"],
               default=st.session_state.user_data["family_history"])
  
  st.session_state.user_data.update({
   "name": name, "gender": gender, "age": age, "height": height,
   "weight": weight, "diseases": diseases, "family_history": family_history,
   "edu": edu, "marry": marry, "incm": incm, "alcohol": alcohol,
   "sleep_time": sleep
  })
  
  st.divider()
  st.write("### ğŸ“‹ ì…ë ¥í•˜ì‹  ì •ë³´ê°€ ì •í™•í•©ë‹ˆê¹Œ?")
  
  col1, col2 = st.columns(2)
  with col1:
   if st.button("âœ… ë„¤, ë§ìŠµë‹ˆë‹¤", type="primary", use_container_width=True):
    if not name:
     st.error("ì„±í•¨ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
     st.session_state.data_confirmed = True
     st.rerun()
  with col2:
   if st.button("ğŸ”„ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤", use_container_width=True):
    st.session_state.data_confirmed = False
    st.info("ìƒë‹¨ ì…ë ¥ë€ì—ì„œ ë‚´ìš©ì„ ìˆ˜ì •í•´ ì£¼ì„¸ìš”.")

  if st.session_state.data_confirmed:
   st.success("âœ… ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
   if st.button("ë‹¤ìŒ ë‹¨ê³„: ì •ì‹ ê±´ê°• ì„¤ë¬¸ â¡", type="primary", use_container_width=True):
    st.session_state.step = 2
    st.rerun()
  st.markdown('</div>', unsafe_allow_html=True)

# --- STEP 2: ì •ì‹ ê±´ê°• ì„¤ë¬¸ ---
elif st.session_state.step == 2:
 SURVEY_DATA = {
  1: {
   "title": "ğŸ“‹ PHQ-9 (ìš°ìš¸ì¦ ì„¤ë¬¸)",
   "questions": [
    "1. ì¼ì„ í•˜ëŠ” ê²ƒì— ëŒ€í•œ í¥ë¯¸ë‚˜ ì¬ë¯¸ê°€ ê±°ì˜ ì—†ìŒ",
    "2. ê¸°ë¶„ì´ ê°€ë¼ì•‰ê±°ë‚˜ ìš°ìš¸í•˜ê±°ë‚˜ í¬ë§ì´ ì—†ë‹¤ê³  ëŠê¼ˆë‹¤",
    "3. ì ë“¤ê¸° ì–´ë µê±°ë‚˜ ìì£¼ ê¹¨ê±°ë‚˜ ë„ˆë¬´ ë§ì´ ì¤ë‹¤",
    "4. í”¼ê³¤í•˜ê³  ê¸°ë ¥ì´ ê±°ì˜ ì—†ì—ˆë‹¤",
    "5. ì‹ìš•ì´ ì €í•˜ë˜ê±°ë‚˜ ê³¼ì‹ì„ í–ˆë‹¤",
    "6. ìì‹ ì´ ì‹¤íŒ¨ìë¼ê³  ëŠë¼ê±°ë‚˜ ìì‹  ë˜ëŠ” ê°€ì¡±ì„ ì‹¤ë§ì‹œì¼°ë‹¤",
    "7. ì‹ ë¬¸ì„ ì½ê±°ë‚˜ TVë¥¼ ë³´ëŠ” ê²ƒê³¼ ê°™ì€ ì¼ì— ì§‘ì¤‘í•˜ê¸° ì–´ë ¤ì› ë‹¤",
    "8. ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ì•Œì•„ì±Œ ì •ë„ë¡œ ë„ˆë¬´ ëŠë¦¬ê²Œ ì›€ì§ì´ê±°ë‚˜ ë§ì„ í–ˆë‹¤",
    "9. ìì‹ ì„ í•´ì¹˜ê±°ë‚˜ ì°¨ë¼ë¦¬ ì£½ëŠ” ê²ƒì´ ë‚«ê² ë‹¤ëŠ” ìƒê°ì„ í–ˆë‹¤"
   ],
   "options": ["ì „í˜€ ì•„ë‹ˆë‹¤", "ì—¬ëŸ¬ ë‚  ë™ì•ˆ", "ì¼ì£¼ì¼ ì´ìƒ", "ê±°ì˜ ë§¤ì¼", "ëª¨ë¦„, ë¬´ì‘ë‹µ"],
   "key": "PHQ9"
  },
  2: {
   "title": "ğŸ˜° GAD-7 (ë¶ˆì•ˆë„ ì„¤ë¬¸)",
   "questions": [
    "1. ì´ˆì¡°í•˜ê±°ë‚˜ ë¶ˆì•ˆí•˜ê±°ë‚˜ ì¡°ë§ˆì¡°ë§ˆí•˜ê²Œ ëŠë‚€ë‹¤",
    "2. ê±±ì •í•˜ëŠ” ê²ƒì„ ë©ˆì¶”ê±°ë‚˜ ì¡°ì ˆí•  ìˆ˜ ì—†ë‹¤",
    "3. ì—¬ëŸ¬ ê°€ì§€ ê²ƒë“¤ì— ëŒ€í•´ ê±±ì •ì„ ë„ˆë¬´ ë§ì´ í•œë‹¤",
    "4. í¸í•˜ê²Œ ìˆê¸°ê°€ ì–´ë µë‹¤",
    "5. ë„ˆë¬´ ì•ˆì ˆë¶€ì ˆëª»í•´ì„œ ê°€ë§Œíˆ ìˆê¸° í˜ë“¤ë‹¤",
    "6. ì‰½ê²Œ ì§œì¦ì´ ë‚˜ê±°ë‚˜ ì‰½ê²Œ ì„±ì„ ë‚¸ë‹¤",
    "7. ë§ˆì¹˜ ë”ì°í•œ ì¼ì´ ì¼ì–´ë‚  ê²ƒì²˜ëŸ¼ ë‘ë µê²Œ ëŠë‚€ë‹¤"
   ],
   "options": ["ì „í˜€ ì•„ë‹ˆë‹¤", "ë©°ì¹  ë™ì•ˆ", "7ì¼ ì´ìƒ", "ê±°ì˜ ë§¤ì¼"],
   "key": "GAD7"
  },
  3: {
   "title": "ğŸ˜“ BP1 (ìŠ¤íŠ¸ë ˆìŠ¤ ì¸ì§€)",
   "questions": ["í‰ì†Œ ì¼ìƒìƒí™œ ì¤‘ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ì–´ëŠ ì •ë„ ëŠë¼ì‹­ë‹ˆê¹Œ?"],
   "options": ["1. ê±°ì˜ ëŠë¼ì§€ ì•ŠìŒ", "2. ì¡°ê¸ˆ ëŠë¼ëŠ” í¸ì´ë‹¤", "3. ë§ì´ ëŠë¼ëŠ” í¸ì´ë‹¤", "4. ëŒ€ë‹¨íˆ ë§ì´ ëŠë‚€ë‹¤"],
   "key": "BP1"
  },
  4: {
   "title": "ğŸ’ª EQ5D (ì‚¶ì˜ ì§ˆ)",
   "questions": ["4-1. ìš´ë™ëŠ¥ë ¥", "4-2. ìê¸°ê´€ë¦¬", "4-3. ì¼ìƒí™œë™", "4-4. í†µì¦/ë¶ˆí¸", "4-5. ë¶ˆì•ˆ/ìš°ìš¸"],
   "options_per_question": [
    ["1. ê±·ëŠ”ë° ì§€ì¥ì´ ì—†ìŒ", "2. ê±·ëŠ”ë° ë‹¤ì†Œ ì§€ì¥ì´ ìˆìŒ", "3. ì¢…ì¼ ëˆ„ì›Œ ìˆì–´ì•¼ í•¨"],
    ["1. ëª©ìš•ì´ë‚˜ ì˜· ì…ëŠ”ë° ì§€ì¥ ì—†ìŒ", "2. ëª©ìš•ì´ë‚˜ ì˜· ì…ëŠ”ë° ë‹¤ì†Œ ì§€ì¥ ìˆìŒ", "3. í˜¼ì ëª©ìš•í•˜ê±°ë‚˜ ì˜· ì…ê¸° í˜ë“¦"],
    ["1. ì¼ìƒ í™œë™ì— ì§€ì¥ ì—†ìŒ", "2. ì¼ìƒ í™œë™ì— ë‹¤ì†Œ ì§€ì¥ ìˆìŒ", "3. ì¼ìƒ í™œë™ì„ í•  ìˆ˜ ì—†ìŒ"],
    ["1. í†µì¦ì´ë‚˜ ë¶ˆí¸ê° ì—†ìŒ", "2. ë‹¤ì†Œ í†µì¦ì´ë‚˜ ë¶ˆí¸ê° ìˆìŒ", "3. ë§¤ìš° ì‹¬í•œ í†µì¦ì´ë‚˜ ë¶ˆí¸ê° ìˆìŒ"],
    ["1. ë¶ˆì•ˆí•˜ê±°ë‚˜ ìš°ìš¸í•˜ì§€ ì•ŠìŒ", "2. ë‹¤ì†Œ ë¶ˆì•ˆí•˜ê±°ë‚˜ ìš°ìš¸í•¨", "3. ë§¤ìš° ë¶ˆì•ˆí•˜ê±°ë‚˜ ìš°ìš¸í•¨"]
   ],
   "key": "EQ5D"
  }
 }
 
 curr = SURVEY_DATA[st.session_state.sub_step]
 q_idx = st.session_state.q_idx
 
 with st.container():
  st.markdown('<div class="card-content">', unsafe_allow_html=True)
  st.markdown(f'<h3 style="color:#22c55e; margin-bottom:5px;">{curr["title"]}</h3>', unsafe_allow_html=True)
  
  
  total_q = len(curr['questions'])
  st.progress((q_idx + 1) / total_q)
  st.caption(f"ë¬¸í•­ {q_idx + 1} / {total_q}")
  
  st.markdown(f"#### {curr['questions'][q_idx]}")
  
  opts = (curr["options_per_question"][q_idx] if "options_per_question" in curr else curr["options"])
  
  answer = st.radio("Select an answer", opts, key=f"q_{st.session_state.sub_step}_{q_idx}", label_visibility="collapsed")
  st.session_state.survey_answers[curr["key"]][f"q{q_idx}"] = answer
  
  st.markdown("<br>", unsafe_allow_html=True)
  
  b1, b2 = st.columns(2)
  with b1:
   if st.button("â¬… ì´ì „ ì§ˆë¬¸", use_container_width=True):
    if q_idx > 0:
     st.session_state.q_idx -= 1
    elif st.session_state.sub_step > 1:
     st.session_state.sub_step -= 1
     st.session_state.q_idx = len(SURVEY_DATA[st.session_state.sub_step]["questions"]) - 1
    else:
     st.session_state.step = 1
    st.rerun()
  
  with b2:
   if q_idx < len(curr["questions"]) - 1:
    button_text = "ë‹¤ìŒ ì§ˆë¬¸ â¡"
   elif st.session_state.sub_step < 4:
    button_text = "ë‹¤ìŒ ì„¤ë¬¸ â¡"
   else:
    button_text = "ë¶„ì„ ê²°ê³¼ ë³´ê¸° ğŸ¯"
   
   if st.button(button_text, type="primary", use_container_width=True):
    if q_idx < len(curr["questions"]) - 1:
     st.session_state.q_idx += 1
    elif st.session_state.sub_step < 4:
     st.session_state.sub_step += 1
     st.session_state.q_idx = 0
    else:
     st.session_state.step = 3
    st.rerun()
  st.markdown('</div>', unsafe_allow_html=True)

# --- STEP 3: AI ë¶„ì„ ë¦¬í¬íŠ¸ ---
elif st.session_state.step == 3:
 st.markdown("<h2 style='text-align:center; margin-bottom:30px;'>ğŸ“Š AI ê±´ê°• ë¶„ì„ ë¦¬í¬íŠ¸</h2>", unsafe_allow_html=True)
 
 u = st.session_state.user_data
 bmi = u['weight'] / ((u['height']/100)**2)
 # ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜ì—ì„œ bp1_scoreë„ ê°€ì ¸ì˜µë‹ˆë‹¤.
 phq, gad, bp1_score, eq5d = calculate_scores()
 
 # ìš”ì•½ ë°”ì— ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜(bp1_score)ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.
 st.markdown(f"""
 <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      color: white; padding: 20px; border-radius: 15px; margin-bottom: 20px;">
  <h3 style="margin:0; color: white;">ğŸ‘¤ {u['name']}ë‹˜ì˜ ê±´ê°• í”„ë¡œí•„</h3>
  <p style="margin:5px 0; color: white;">ë‚˜ì´: {u['age']}ì„¸ | ì„±ë³„: {u['gender']} | BMI: {bmi:.1f}</p>
  <p style="margin:5px 0; color: white;">ìš°ìš¸: {phq}ì  | ë¶ˆì•ˆ: {gad}ì  | ìŠ¤íŠ¸ë ˆìŠ¤: {bp1_score}ì  | ì‚¶ì˜ ì§ˆ: {eq5d:.2f}</p>
 </div>
 """, unsafe_allow_html=True)
 
 preds = get_predictions()
 high_risks, mid_risks = [], []
 risk_summary_text = []
 
 for d_name, res in preds.items():
  prob, threshold = res['prob'], res['threshold']
  score = int(prob * 100)
  
  if prob >= threshold: level = "ë†’ìŒ"; high_risks.append(d_name)
  elif prob >= threshold * 0.7: level = "ì¤‘ê°„"; mid_risks.append(d_name)
  else: level = "ë‚®ìŒ"
  
  if level in ["ë†’ìŒ", "ì¤‘ê°„"]: risk_summary_text.append(f"{d_name}({level})")
  
  theme = LEVEL_THEMES[level]
  st.markdown(f"""
  <div class="disease-item-card">
   <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 12px;">
    <span style="font-weight: bold; font-size: 1.2rem; color: #334155;">{theme['emoji']} {d_name}</span>
    <div style="text-align: right;">
     <span style="color: {theme['color']}; font-weight: bold; font-size: 1.2rem;">{level}</span>
     <span style="color: #64748b; font-size: 0.9rem; margin-left: 8px;">ìœ„í—˜ë„ {score}ì </span>
    </div>
   </div>
   <div style="width: 100%; background-color: #f1f5f9; border-radius: 10px; height: 14px; overflow: hidden;">
    <div style="width: {score}%; background-color: {theme['color']}; height: 100%; border-radius: 10px;"></div>
   </div>
   <p style="margin-top: 10px; color: #64748b; font-size: 0.9rem;">ë°œë³‘ í™•ë¥ : {prob:.1%} | ê¸°ì¤€ ì„ê³„ê°’: {threshold:.1%}</p>
  </div>
  """, unsafe_allow_html=True)

 st.session_state.risks_summary = ", ".join(risk_summary_text) if risk_summary_text else "ì •ìƒ"

 st.write("---")
 st.markdown("### ğŸ’¡ ì¢…í•© ì˜ê²¬")
 if high_risks: st.error(f"**ê³ ìœ„í—˜ ì§ˆí™˜**: {', '.join(high_risks)} - ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
 if mid_risks: st.warning(f"**ì¤‘ìœ„í—˜ ì§ˆí™˜**: {', '.join(mid_risks)} - ìƒí™œìŠµê´€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
 if not high_risks and not mid_risks: st.success("ëª¨ë“  ì§ˆí™˜ì´ ì €ìœ„í—˜ì…ë‹ˆë‹¤. í˜„ì¬ ìƒíƒœë¥¼ ìœ ì§€í•˜ì„¸ìš”!")
 
 st.write("---")
 c1, c2 = st.columns(2)
 with c1:
  if st.button("ğŸ™ï¸ AI ìƒë‹´ ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
   st.session_state.chat_history = [{"role": "ai", "content": f"ì•ˆë…•í•˜ì„¸ìš” {st.session_state.user_data['name']}ë‹˜. ë¶„ì„ ê²°ê³¼ {st.session_state.risks_summary} ìœ„í—˜ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ì ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}]
   st.session_state.step = 4; st.rerun()
 with c2:
  if st.button("ğŸ”„ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°", use_container_width=True):
   for key in list(st.session_state.keys()): del st.session_state[key]
   st.rerun()

# --- STEP 4: AI ìŒì„± ì±—ë´‡ ìƒë‹´ (Edge TTS ì ìš©) ---
elif st.session_state.step == 4:
 
 # Edge TTS ìŒì„± ìƒì„± í•¨ìˆ˜
 async def generate_edge_tts_async(text):
  """Edge TTSë¡œ ìŒì„± ìƒì„± (ë¹„ë™ê¸°)"""
  try:
   communicate = edge_tts.Communicate(text, "ko-KR-SunHiNeural")
   audio_data = b""
   
   async for chunk in communicate.stream():
    if chunk["type"] == "audio":
     audio_data += chunk["data"]
   
   return audio_data
  except Exception as e:
   return None
 
 def generate_edge_tts(text):
  """Edge TTS ë™ê¸° ë˜í¼ í•¨ìˆ˜"""
  try:
   # ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„± ë° ì‹¤í–‰
   loop = asyncio.new_event_loop()
   asyncio.set_event_loop(loop)
   audio_data = loop.run_until_complete(generate_edge_tts_async(text))
   loop.close()
   return audio_data
  except Exception as e:
   return None
 
 with st.container():
  st.markdown('<div class="card-content">', unsafe_allow_html=True)
  st.subheader("ğŸ¤– AI ê±´ê°• ë¹„ì„œ")
  
  # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ ì˜ì—­
  chat_container = st.container()
  with chat_container:
   for idx, msg in enumerate(st.session_state.chat_history):
    if msg["role"] == "user":
     st.markdown(f'<div class="chat-bubble-user">ğŸ‘¤ {msg["content"]}</div>', unsafe_allow_html=True)
    else:
     st.markdown(f'<div class="chat-bubble-ai">ğŸ¤– {msg["content"]}</div>', unsafe_allow_html=True)
     if "audio" in msg: 
      st.audio(msg["audio"], format="audio/mp3")
  
  # ì…ë ¥ ì˜ì—­
  col1, col2 = st.columns([4, 1])
  with col2:
   st.write("ğŸ™ï¸ ìŒì„±ì…ë ¥")
   voice_msg = speech_to_text(language='ko', just_once=True, key='stt_final')
  with col1:
   user_msg = st.chat_input("ì¦ìƒì´ë‚˜ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”.")

  final_input = voice_msg if voice_msg else user_msg

  if final_input:
   # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
   st.session_state.chat_history.append({"role": "user", "content": final_input})
   
   # AI ì‘ë‹µ ìƒì„± ì˜ì—­
   with chat_container:
    st.markdown(f'<div class="chat-bubble-user">ğŸ‘¤ {final_input}</div>', unsafe_allow_html=True)
    ai_message_placeholder = st.empty()
   
   try:
    # LLM ì„¤ì •
    llm = ChatOpenAI(
     model="gpt-4o",
     api_key=OPENAI_API_KEY,
     temperature=0.7,
     streaming=True
    )
    
    u = st.session_state.user_data
    phq, gad, _, _ = calculate_scores()
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€
    sys_msg = (f"ê±´ê°• ìƒë‹´ì‚¬. ëŒ€ìƒ: {u['name']}({u['age']}ì„¸). "
               f"ìœ„í—˜: {st.session_state.risks_summary}. "
               f"ìš°ìš¸{phq}ì , ë¶ˆì•ˆ{gad}ì . ì¹œì ˆí•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€.")
    
    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
    full_response = ""
    
    for chunk in llm.stream([
     SystemMessage(content=sys_msg), 
     HumanMessage(content=final_input)
    ]):
     full_response += chunk.content
     ai_message_placeholder.markdown(
      f'<div class="chat-bubble-ai">ğŸ¤– {full_response}â–Œ</div>', 
      unsafe_allow_html=True
     )
    
    # ìµœì¢… ì‘ë‹µ í‘œì‹œ
    ai_message_placeholder.markdown(
     f'<div class="chat-bubble-ai">ğŸ¤– {full_response}</div>', 
     unsafe_allow_html=True
    )
    
    # Edge TTSë¡œ ìŒì„± ìƒì„±
    audio_data = None
    with st.spinner("ğŸ”Š ìŒì„± ìƒì„± ì¤‘..."):
     try:
      audio_data = generate_edge_tts(full_response)
      
      if audio_data:
       with chat_container:
        st.audio(audio_data, format="audio/mp3")
      else:
       st.warning("ìŒì„± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
       
     except Exception as tts_error:
      st.warning(f"ìŒì„± ìƒì„± ì‹¤íŒ¨: {tts_error}")
    
    # íˆìŠ¤í† ë¦¬ ì €ì¥
    chat_entry = {"role": "ai", "content": full_response}
    if audio_data:
     chat_entry["audio"] = audio_data
    
    st.session_state.chat_history.append(chat_entry)
    st.rerun()
    
   except Exception as e:
    st.error(f"ìƒë‹´ ì¤‘ ì˜¤ë¥˜: {e}")

  if st.button("â¬… ê²°ê³¼ ë¦¬í¬íŠ¸ë¡œ ëŒì•„ê°€ê¸°"): 
   st.session_state.step = 3
   st.rerun()
  
  st.markdown('</div>', unsafe_allow_html=True)